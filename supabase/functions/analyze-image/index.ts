import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

const DETAIL_LEVEL_INSTRUCTIONS: Record<string, string> = {
  short: `Seja MUITO conciso. Cada se√ß√£o deve ter no m√°ximo 1-2 frases curtas.`,
  standard: `Forne√ßa uma an√°lise equilibrada. Cada se√ß√£o deve ter 2-4 frases.`,
  detailed: `Forne√ßa uma an√°lise completa e detalhada. Explore cada se√ß√£o em profundidade com explica√ß√µes extensas.`,
};

const SYSTEM_PROMPT = `Voc√™ √© um assistente especializado em an√°lise de imagens. Sua tarefa √© analisar imagens enviadas pelo usu√°rio e fornecer uma an√°lise completa, organizada e confi√°vel.

IMPORTANTE: Voc√™ DEVE seguir EXATAMENTE este formato na sua resposta:

üìå Contexto da imagem
[Descreva o que a imagem representa, o tipo de conte√∫do (print, documento, foto, erro, aviso, interface, etc.) e a situa√ß√£o prov√°vel]

üìù Texto identificado na imagem (OCR)
[Extraia TODO o texto vis√≠vel na imagem, mantendo fidelidade ao texto original. Se n√£o houver texto, informe: "Nenhum texto identificado na imagem."]

üìñ Explica√ß√£o e interpreta√ß√£o
[Explique o conte√∫do da imagem e do texto de forma clara, objetiva e acess√≠vel. N√£o fa√ßa suposi√ß√µes exageradas.]

üí° Poss√≠veis usos ou aplica√ß√µes
[Liste poss√≠veis usos profissionais, acad√™micos ou pr√°ticos. Se n√£o for aplic√°vel, escreva: "N√£o aplic√°vel para esta imagem."]

‚ö†Ô∏è Observa√ß√µes relevantes
[Inclua alertas, limita√ß√µes, pontos de aten√ß√£o ou erros comuns de interpreta√ß√£o. Se n√£o houver, escreva: "Nenhuma observa√ß√£o adicional."]

üîé Fontes ou refer√™ncias
[Cite fontes conhecidas quando aplic√°vel. N√£o invente links. Se n√£o existirem fontes diretas, informe: "Explica√ß√£o baseada em conhecimento conceitual."]

REGRAS:
- Sempre responda em portugu√™s brasileiro
- Mantenha o formato exato com os emojis
- Seja preciso e objetivo
- N√£o invente informa√ß√µes
- Se o usu√°rio fornecer um contexto ou pergunta espec√≠fica, priorize essa informa√ß√£o na an√°lise`;

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { imageBase64, mimeType, userContext, detailLevel = "standard", previousAnalysis } = await req.json();

    if (!imageBase64) {
      return new Response(
        JSON.stringify({ error: "Nenhuma imagem fornecida" }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY");
    if (!LOVABLE_API_KEY) {
      console.error("LOVABLE_API_KEY not configured");
      return new Response(
        JSON.stringify({ error: "Configura√ß√£o do servidor incompleta" }),
        { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    const detailInstruction = DETAIL_LEVEL_INSTRUCTIONS[detailLevel] || DETAIL_LEVEL_INSTRUCTIONS.standard;

    let userMessage = `Analise esta imagem seguindo o formato especificado.\n\n${detailInstruction}`;
    
    if (previousAnalysis) {
      userMessage = `An√°lise anterior:\n${previousAnalysis}\n\nPergunta do usu√°rio: "${userContext}"\n\nResponda a pergunta do usu√°rio baseado na an√°lise anterior e na imagem. Mantenha o mesmo formato estruturado.\n\n${detailInstruction}`;
    } else if (userContext) {
      userMessage = `O usu√°rio quer saber: "${userContext}"\n\nAnalise esta imagem considerando essa solicita√ß√£o, mas ainda seguindo o formato completo especificado.\n\n${detailInstruction}`;
    }

    console.log("Calling Lovable AI for image analysis with detail level:", detailLevel);

    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash",
        messages: [
          { role: "system", content: SYSTEM_PROMPT },
          {
            role: "user",
            content: [
              { type: "text", text: userMessage },
              {
                type: "image_url",
                image_url: {
                  url: `data:${mimeType};base64,${imageBase64}`,
                },
              },
            ],
          },
        ],
      }),
    });

    if (!response.ok) {
      if (response.status === 429) {
        console.error("Rate limit exceeded");
        return new Response(
          JSON.stringify({ error: "Limite de requisi√ß√µes excedido. Tente novamente em alguns minutos." }),
          { status: 429, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
      if (response.status === 402) {
        console.error("Payment required");
        return new Response(
          JSON.stringify({ error: "Cr√©ditos insuficientes. Adicione cr√©ditos √† sua conta." }),
          { status: 402, headers: { ...corsHeaders, "Content-Type": "application/json" } }
        );
      }
      const errorText = await response.text();
      console.error("AI gateway error:", response.status, errorText);
      return new Response(
        JSON.stringify({ error: "Erro ao processar a imagem" }),
        { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    const data = await response.json();
    const analysisResult = data.choices?.[0]?.message?.content;

    if (!analysisResult) {
      console.error("No content in AI response");
      return new Response(
        JSON.stringify({ error: "Resposta inv√°lida da IA" }),
        { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    // Generate quick summary (first 2-3 sentences of the context section)
    let quickSummary = "";
    const contextMatch = analysisResult.match(/üìå Contexto da imagem\n([^\nüìù]+)/);
    if (contextMatch) {
      const contextText = contextMatch[1].trim();
      const sentences = contextText.split(/[.!?]+/).filter(Boolean).slice(0, 2);
      quickSummary = sentences.join(". ").trim();
      if (quickSummary && !quickSummary.endsWith(".")) {
        quickSummary += ".";
      }
    }

    console.log("Image analysis completed successfully");

    return new Response(
      JSON.stringify({ analysis: analysisResult, quickSummary }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  } catch (error) {
    console.error("Error in analyze-image function:", error);
    return new Response(
      JSON.stringify({ error: error instanceof Error ? error.message : "Erro desconhecido" }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});
